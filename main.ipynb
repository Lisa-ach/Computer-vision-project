{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data_processing import import_images as i\n",
    "from Classification import classification_class as classification\n",
    "from Features_extraction import interest_point_detection as interest_point_detection\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_results_best_methods = {\n",
    "        \"accuracy\" : {},\n",
    "        \"f1-score\" : {},\n",
    "        \"recall\" : {},\n",
    "        \"precision\" : {},\n",
    "        \"roc_auc\" : {}\n",
    "        }\n",
    "\n",
    "name_best_models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Point of interest detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========1. Extract SIFT features from all images=========\n",
      "=========2. Stack all descriptors for clustering (BoVW) =========\n",
      "=========3. Cluster descriptors using KMeans (BoVW approach) =========\n",
      "========= 4. Create feature histograms for each image =========\n",
      "Optimization Logistic Regression\n",
      "Optimization Classification Decision Tree\n",
      "Optimization Random Forest\n",
      "Best method name: LogReg\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.78        86\n",
      "           1       0.62      0.52      0.57        50\n",
      "\n",
      "    accuracy                           0.71       136\n",
      "   macro avg       0.68      0.67      0.67       136\n",
      "weighted avg       0.70      0.71      0.70       136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_features = pd.DataFrame(interest_point_detection.method_SIFT(i.images))\n",
    "df_Y = pd.DataFrame(i.Y)\n",
    "\n",
    "data_SIFT = classification.DataProcessing(df_features, df_Y, stratified=False)\n",
    "env_SIFT = classification.BinaryClassification(data_SIFT, average=\"macro\")\n",
    "metrics_results = env_SIFT.CrossValidationKFold()\n",
    "labels = list(metrics_results['f1-score'].keys())\n",
    "results_train_KFold, results_test_KFold = env_SIFT.createMeansDataframe(metrics_results, labels)\n",
    "results_train_KFold.style.highlight_max(axis=0)\n",
    "\n",
    "best_method_name = env_SIFT.get_best_method(results_test_KFold, \"F1-score\", ens=\"Test\")\n",
    "print(f\"Best method name: {best_method_name}\")\n",
    "name_best_models[\"SIFT + BoW\"] = best_method_name\n",
    "metrics_results, predictions, models = env_SIFT.TrainTest()\n",
    "env_SIFT.evaluate_model(models[best_method_name])\n",
    "metrics_results_best_methods = env_SIFT.get_metrics(models[best_method_name], \"SIFT + BoW\", metrics_results_best_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_features = pd.DataFrame(interest_point_detection.method_SURF(i.images))\n",
    "# df_Y = pd.DataFrame(i.Y)\n",
    "\n",
    "# data_SURF = classification.DataProcessing(df_features, df_Y, stratified=False)\n",
    "# env_SURF = classification.BinaryClassification(data_SURF, average=\"macro\")\n",
    "# metrics_results = env_SURF.CrossValidationKFold()\n",
    "# labels = list(metrics_results['f1-score'].keys())\n",
    "# results_train_KFold, results_test_KFold = env_SURF.createMeansDataframe(metrics_results, labels)\n",
    "# results_train_KFold.style.highlight_max(axis=0)\n",
    "\n",
    "# best_method_name = env_SURF.get_best_method(results_test_KFold, \"F1-score\", ens=\"Test\")\n",
    "# print(f\"Best method name: {best_method_name}\")\n",
    "# name_best_models[\"SURF + BoW\"] = best_method_name\n",
    "# metrics_results, predictions, models = env_SURF.TrainTest()\n",
    "# env_SURF.evaluate_model(models[best_method_name])\n",
    "# metrics_results_best_methods = env_SURF.get_metrics(models[best_method_name], \"SURF + BoW\", metrics_results_best_methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========1. Extract Edge Detection features from all images=========\n",
      "=========2. Convert feature list to DataFrame=========\n",
      "=========3. Normalize features=========\n",
      "   canny_edge_density  sobelx_mean  sobelx_std  sobely_mean  sobely_std  \\\n",
      "0            0.565959     0.564201    0.279468     0.590818    0.374775   \n",
      "1            0.467582     0.677748    0.645522     0.398871    0.281901   \n",
      "2            0.270235     0.769452    0.301940     0.493734    0.294019   \n",
      "3            0.252929     0.576336    0.101811     0.548493    0.323417   \n",
      "4            0.336962     0.502383    0.303101     0.537552    0.315156   \n",
      "\n",
      "   prewitt_edge_density  \n",
      "0              0.346193  \n",
      "1              0.427376  \n",
      "2              0.229059  \n",
      "3              0.183457  \n",
      "4              0.266162  \n",
      "Optimization Logistic Regression\n",
      "Optimization Classification Decision Tree\n",
      "Optimization Random Forest\n",
      "Best method name: LogReg\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        86\n",
      "           1       0.76      0.76      0.76        50\n",
      "\n",
      "    accuracy                           0.82       136\n",
      "   macro avg       0.81      0.81      0.81       136\n",
      "weighted avg       0.82      0.82      0.82       136\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': {'EDGE': 0.8235294117647058},\n",
       " 'f1-score': {'EDGE': 0.8102325581395349},\n",
       " 'recall': {'EDGE': 0.8102325581395349},\n",
       " 'precision': {'EDGE': 0.8102325581395349},\n",
       " 'roc_auc': {'EDGE': 0.8102325581395349}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Features_extraction import edge_detection as edges\n",
    "\n",
    "df_features_edge = edges.features_df\n",
    "\n",
    "data_edge = classification.DataProcessing(df_features_edge, df_Y, stratified=False)\n",
    "env_edge = classification.BinaryClassification(data_edge, average=\"macro\")\n",
    "metrics_results = env_edge.CrossValidationKFold()\n",
    "labels = list(metrics_results['f1-score'].keys())\n",
    "results_train_KFold, results_test_KFold = env_edge.createMeansDataframe(metrics_results, labels)\n",
    "results_train_KFold.style.highlight_max(axis=0)\n",
    "\n",
    "best_method_name = env_edge.get_best_method(results_test_KFold, \"F1-score\", ens=\"Test\")\n",
    "print(f\"Best method name: {best_method_name}\")\n",
    "name_best_models[\"EDGE\"] = best_method_name\n",
    "metrics_results, predictions, models = env_edge.TrainTest()\n",
    "env_edge.evaluate_model(models[best_method_name])\n",
    "metrics_results_best_methods = env_edge.get_metrics(models[best_method_name], \"EDGE\", metrics_results_best_methods)\n",
    "\n",
    "metrics_results_best_methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Overall results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_dc1f4_row0_col1, #T_dc1f4_row0_col2, #T_dc1f4_row0_col3, #T_dc1f4_row0_col4, #T_dc1f4_row0_col5 {\n",
       "  background-color: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_dc1f4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_dc1f4_level0_col0\" class=\"col_heading level0 col0\" >Best models</th>\n",
       "      <th id=\"T_dc1f4_level0_col1\" class=\"col_heading level0 col1\" >accuracy</th>\n",
       "      <th id=\"T_dc1f4_level0_col2\" class=\"col_heading level0 col2\" >f1-score</th>\n",
       "      <th id=\"T_dc1f4_level0_col3\" class=\"col_heading level0 col3\" >recall</th>\n",
       "      <th id=\"T_dc1f4_level0_col4\" class=\"col_heading level0 col4\" >precision</th>\n",
       "      <th id=\"T_dc1f4_level0_col5\" class=\"col_heading level0 col5\" >roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_dc1f4_level0_row0\" class=\"row_heading level0 row0\" >SIFT + BoW</th>\n",
       "      <td id=\"T_dc1f4_row0_col0\" class=\"data row0 col0\" >LogReg</td>\n",
       "      <td id=\"T_dc1f4_row0_col1\" class=\"data row0 col1\" >0.705882</td>\n",
       "      <td id=\"T_dc1f4_row0_col2\" class=\"data row0 col2\" >0.671498</td>\n",
       "      <td id=\"T_dc1f4_row0_col3\" class=\"data row0 col3\" >0.666977</td>\n",
       "      <td id=\"T_dc1f4_row0_col4\" class=\"data row0 col4\" >0.681864</td>\n",
       "      <td id=\"T_dc1f4_row0_col5\" class=\"data row0 col5\" >0.666977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b60c0e7210>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_best_models_all_datasets_macro_f1 = pd.DataFrame(metrics_results_best_methods)\n",
    "df_best_models_all_datasets_macro_f1.insert(0, 'Best models', name_best_models)\n",
    "df_best_models_all_datasets_macro_f1.style.highlight_max(axis=0, subset=df_best_models_all_datasets_macro_f1.columns[1:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

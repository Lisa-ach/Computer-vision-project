{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========1. Extract SIFT features from all images=========\n",
      "=========2. Stack all descriptors for clustering (BoVW) =========\n",
      "=========3. Cluster descriptors using KMeans (BoVW approach) =========\n",
      "========= 4. Create feature histograms for each image =========\n",
      "=========1. Extract Edge Detection features from all images=========\n",
      "=========2. Convert feature list to DataFrame=========\n",
      "=========3. Normalize features=========\n",
      "   canny_edge_density  sobelx_mean  sobelx_std  sobely_mean  sobely_std  \\\n",
      "0            0.616994     0.564201    0.279468     0.590818    0.374775   \n",
      "1            0.548750     0.677748    0.645522     0.398871    0.281901   \n",
      "2            0.258691     0.769452    0.301940     0.493734    0.294019   \n",
      "3            0.420246     0.576336    0.101811     0.548493    0.323417   \n",
      "4            0.420778     0.502383    0.303101     0.537552    0.315156   \n",
      "\n",
      "   prewitt_edge_density  laplacian_edge_density  roberts_edge_density  \\\n",
      "0              0.346193                0.714930              0.293888   \n",
      "1              0.427376                0.589676              0.285890   \n",
      "2              0.229059                0.434176              0.165162   \n",
      "3              0.183457                0.670197              0.184762   \n",
      "4              0.266162                0.579645              0.234748   \n",
      "\n",
      "   lbp_mean   lbp_std  \n",
      "0  0.324047  0.754728  \n",
      "1  0.242334  0.446999  \n",
      "2  0.554279  0.505654  \n",
      "3  0.479217  0.709325  \n",
      "4  0.271384  0.627433  \n"
     ]
    }
   ],
   "source": [
    "from Data_processing import import_images as i\n",
    "from Classification import classification_class as classification\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_results_best_methods = {\n",
    "        \"accuracy\" : {},\n",
    "        \"f1-score\" : {},\n",
    "        \"recall\" : {},\n",
    "        \"precision\" : {},\n",
    "        \"roc_auc\" : {}\n",
    "        }\n",
    "\n",
    "\n",
    "name_best_models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= 5. Classification =========\n",
      "Optimization Logistic Regression\n",
      "Optimization Classification Decision Tree\n",
      "Optimization Random Forest\n",
      "Best method name: LogReg\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.78        86\n",
      "           1       0.61      0.54      0.57        50\n",
      "\n",
      "    accuracy                           0.71       136\n",
      "   macro avg       0.68      0.67      0.67       136\n",
      "weighted avg       0.70      0.71      0.70       136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from Features_extraction import SIFT as SIFT\n",
    "print(\"========= 5. Classification =========\")\n",
    "df_features = pd.DataFrame(SIFT.feature_vectors)\n",
    "df_Y = pd.DataFrame(i.Y)\n",
    "\n",
    "data_SIFT = classification.DataProcessing(df_features, df_Y, stratified=False)\n",
    "env_SIFT = classification.BinaryClassification(data_SIFT, average=\"macro\")\n",
    "metrics_results = env_SIFT.CrossValidationKFold()\n",
    "labels = list(metrics_results['f1-score'].keys())\n",
    "results_train_KFold, results_test_KFold = env_SIFT.createMeansDataframe(metrics_results, labels)\n",
    "results_train_KFold.style.highlight_max(axis=0)\n",
    "\n",
    "best_method_name = env_SIFT.get_best_method(results_test_KFold, \"F1-score\", ens=\"Test\")\n",
    "print(f\"Best method name: {best_method_name}\")\n",
    "name_best_models[\"SIFT + BoW\"] = best_method_name\n",
    "metrics_results, predictions, models = env_SIFT.TrainTest()\n",
    "env_SIFT.evaluate_model(models[best_method_name])\n",
    "metrics_results_best_methods = env_SIFT.get_metrics(models[best_method_name], \"SIFT + BoW\", metrics_results_best_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': {'SIFT + BoW': 0.7058823529411765},\n",
       " 'f1-score': {'SIFT + BoW': 0.6748744919913938},\n",
       " 'recall': {'SIFT + BoW': 0.6711627906976745},\n",
       " 'precision': {'SIFT + BoW': 0.6818181818181819},\n",
       " 'roc_auc': {'SIFT + BoW': 0.6711627906976745}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_results_best_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= 4. Classification =========\n",
      "Optimization Logistic Regression\n",
      "Optimization Classification Decision Tree\n",
      "Optimization Random Forest\n",
      "Best method name: LogReg\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.86        86\n",
      "           1       0.74      0.84      0.79        50\n",
      "\n",
      "    accuracy                           0.83       136\n",
      "   macro avg       0.82      0.83      0.82       136\n",
      "weighted avg       0.84      0.83      0.83       136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from Features_extraction import edge_detection as edges\n",
    "print(\"========= 4. Classification =========\")\n",
    "df_features_edge = edges.features_df\n",
    "df_Y = pd.DataFrame(i.Y)\n",
    "assert len(df_features_edge) == len(df_Y), \"Mismatch entre features et labels !\"\n",
    "\n",
    "\n",
    "\n",
    "data_edge = classification.DataProcessing(df_features_edge, df_Y, stratified=False)\n",
    "env_edge = classification.BinaryClassification(data_edge, average=\"macro\")\n",
    "metrics_results = env_edge.CrossValidationKFold()\n",
    "labels = list(metrics_results['f1-score'].keys())\n",
    "results_train_KFold, results_test_KFold = env_edge.createMeansDataframe(metrics_results, labels)\n",
    "results_train_KFold.style.highlight_max(axis=0)\n",
    "\n",
    "best_method_name = env_edge.get_best_method(results_test_KFold, \"F1-score\", ens=\"Test\")\n",
    "print(f\"Best method name: {best_method_name}\")\n",
    "name_best_models[\"EDGE\"] = best_method_name\n",
    "metrics_results, predictions, models = env_edge.TrainTest()\n",
    "env_edge.evaluate_model(models[best_method_name])\n",
    "metrics_results_best_methods = env_edge.get_metrics(models[best_method_name], \"EDGE\", metrics_results_best_methods)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': {'SIFT + BoW': 0.7058823529411765, 'EDGE': 0.8308823529411765},\n",
       " 'f1-score': {'SIFT + BoW': 0.6748744919913938, 'EDGE': 0.8228263947890115},\n",
       " 'recall': {'SIFT + BoW': 0.6711627906976745, 'EDGE': 0.8327906976744186},\n",
       " 'precision': {'SIFT + BoW': 0.6818181818181819, 'EDGE': 0.8177881412391739},\n",
       " 'roc_auc': {'SIFT + BoW': 0.6711627906976745, 'EDGE': 0.8327906976744185}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_results_best_methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========  Applying Preprocessing to Images =========\n"
     ]
    }
   ],
   "source": [
    "from Data_processing import data_preprocessing as dp\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Apply preprocessing to all images\n",
    "print(\"=========  Applying Preprocessing to Images =========\")\n",
    "\n",
    "# Load images \n",
    "target_size = (128, 128)  # Mettre la taille désirée\n",
    "\n",
    "preprocessed_images = [cv2.resize(img, target_size, interpolation=cv2.INTER_AREA) for img in preprocessed_images]\n",
    "preprocessed_images = np.array(preprocessed_images)\n",
    "\n",
    "# Convert back to NumPy array \n",
    "preprocessed_images = np.array(preprocessed_images)\n",
    "\n",
    "# Update dataset with preprocessed images\n",
    "i.images = preprocessed_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Extracting Edge Detection Features =========\n",
      "Optimization Logistic Regression\n",
      "Optimization Classification Decision Tree\n",
      "Optimization Random Forest\n",
      "Best method name for Edge Detection: LogReg\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.86        86\n",
      "           1       0.74      0.84      0.79        50\n",
      "\n",
      "    accuracy                           0.83       136\n",
      "   macro avg       0.82      0.83      0.82       136\n",
      "weighted avg       0.84      0.83      0.83       136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from Features_extraction import edge_detection as edges\n",
    "\n",
    "print(\"========= Extracting Edge Detection Features =========\")\n",
    "\n",
    "df_features_edge = edges.features_df\n",
    "df_Y = pd.DataFrame(i.Y)\n",
    "\n",
    "assert len(df_features_edge) == len(df_Y), \"Mismatch between features and labels!\"\n",
    "\n",
    "data_edge = classification.DataProcessing(df_features_edge, df_Y, stratified=False)\n",
    "env_edge = classification.BinaryClassification(data_edge, average=\"macro\")\n",
    "metrics_results = env_edge.CrossValidationKFold()\n",
    "labels = list(metrics_results['f1-score'].keys())\n",
    "results_train_KFold, results_test_KFold = env_edge.createMeansDataframe(metrics_results, labels)\n",
    "results_train_KFold.style.highlight_max(axis=0)\n",
    "\n",
    "best_method_name = env_edge.get_best_method(results_test_KFold, \"F1-score\", ens=\"Test\")\n",
    "print(f\"Best method name for Edge Detection: {best_method_name}\")\n",
    "name_best_models[\"EDGE (Preprocessed)\"] = best_method_name\n",
    "metrics_results, predictions, models = env_edge.TrainTest()\n",
    "env_edge.evaluate_model(models[best_method_name])\n",
    "metrics_results_best_methods = env_edge.get_metrics(models[best_method_name], \"EDGE (Preprocessed)\", metrics_results_best_methods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Comparison of Classification Results =========\n",
      "                     accuracy  f1-score    recall  precision   roc_auc\n",
      "SIFT + BoW           0.705882  0.674874  0.671163   0.681818  0.671163\n",
      "EDGE                 0.830882  0.822826  0.832791   0.817788  0.832791\n",
      "EDGE (Preprocessed)  0.830882  0.822826  0.832791   0.817788  0.832791\n"
     ]
    }
   ],
   "source": [
    "# Convert results to DataFrame for better visualization\n",
    "df_results = pd.DataFrame(metrics_results_best_methods)\n",
    "print(\"\\n========= Comparison of Classification Results =========\")\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

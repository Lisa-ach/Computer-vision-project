{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data_processing import import_images as i\n",
    "from Classification import classification_class as classification\n",
    "#from Features_extraction import SIFT as SIFT\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_results_best_methods = {\n",
    "        \"accuracy\" : {},\n",
    "        \"f1-score\" : {},\n",
    "        \"recall\" : {},\n",
    "        \"precision\" : {},\n",
    "        \"roc_auc\" : {}\n",
    "        }\n",
    "\n",
    "\n",
    "name_best_models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"========= 5. Classification =========\")\n",
    "df_features = pd.DataFrame(SIFT.feature_vectors)\n",
    "df_Y = pd.DataFrame(i.Y)\n",
    "\n",
    "data_SIFT = classification.DataProcessing(df_features, df_Y, stratified=False)\n",
    "env_SIFT = classification.BinaryClassification(data_SIFT, average=\"macro\")\n",
    "metrics_results = env_SIFT.CrossValidationKFold()\n",
    "labels = list(metrics_results['f1-score'].keys())\n",
    "results_train_KFold, results_test_KFold = env_SIFT.createMeansDataframe(metrics_results, labels)\n",
    "results_train_KFold.style.highlight_max(axis=0)\n",
    "\n",
    "best_method_name = env_SIFT.get_best_method(results_test_KFold, \"F1-score\", ens=\"Test\")\n",
    "print(f\"Best method name: {best_method_name}\")\n",
    "name_best_models[\"SIFT + BoW\"] = best_method_name\n",
    "metrics_results, predictions, models = env_SIFT.TrainTest()\n",
    "env_SIFT.evaluate_model(models[best_method_name])\n",
    "metrics_results_best_methods = env_SIFT.get_metrics(models[best_method_name], \"SIFT + BoW\", metrics_results_best_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_results_best_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========1. Extract Edge Detection features from all images=========\n",
      "=========2. Convert feature list to DataFrame=========\n",
      "=========3. Normalize features=========\n",
      "   canny_edge_density  sobelx_mean  sobelx_std  sobely_mean  sobely_std  \\\n",
      "0            0.565959     0.564201    0.279468     0.590818    0.374775   \n",
      "1            0.467582     0.677748    0.645522     0.398871    0.281901   \n",
      "2            0.270235     0.769452    0.301940     0.493734    0.294019   \n",
      "3            0.252929     0.576336    0.101811     0.548493    0.323417   \n",
      "4            0.336962     0.502383    0.303101     0.537552    0.315156   \n",
      "\n",
      "   prewitt_edge_density  \n",
      "0              0.346193  \n",
      "1              0.427376  \n",
      "2              0.229059  \n",
      "3              0.183457  \n",
      "4              0.266162  \n",
      "Optimization Logistic Regression\n",
      "Optimization Classification Decision Tree\n",
      "Optimization Random Forest\n",
      "Best method name: LogReg\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        86\n",
      "           1       0.76      0.76      0.76        50\n",
      "\n",
      "    accuracy                           0.82       136\n",
      "   macro avg       0.81      0.81      0.81       136\n",
      "weighted avg       0.82      0.82      0.82       136\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': {'EDGE': 0.8235294117647058},\n",
       " 'f1-score': {'EDGE': 0.8102325581395349},\n",
       " 'recall': {'EDGE': 0.8102325581395349},\n",
       " 'precision': {'EDGE': 0.8102325581395349},\n",
       " 'roc_auc': {'EDGE': 0.8102325581395349}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Features_extraction import edge_detection as edges\n",
    "\n",
    "df_features_edge = edges.features_df\n",
    "df_Y = pd.DataFrame(i.Y)\n",
    "\n",
    "\n",
    "data_edge = classification.DataProcessing(df_features_edge, df_Y, stratified=False)\n",
    "env_edge = classification.BinaryClassification(data_edge, average=\"macro\")\n",
    "metrics_results = env_edge.CrossValidationKFold()\n",
    "labels = list(metrics_results['f1-score'].keys())\n",
    "results_train_KFold, results_test_KFold = env_edge.createMeansDataframe(metrics_results, labels)\n",
    "results_train_KFold.style.highlight_max(axis=0)\n",
    "\n",
    "best_method_name = env_edge.get_best_method(results_test_KFold, \"F1-score\", ens=\"Test\")\n",
    "print(f\"Best method name: {best_method_name}\")\n",
    "name_best_models[\"EDGE\"] = best_method_name\n",
    "metrics_results, predictions, models = env_edge.TrainTest()\n",
    "env_edge.evaluate_model(models[best_method_name])\n",
    "metrics_results_best_methods = env_edge.get_metrics(models[best_method_name], \"EDGE\", metrics_results_best_methods)\n",
    "\n",
    "\n",
    "metrics_results_best_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

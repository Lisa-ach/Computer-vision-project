{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2722a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "notebook_dir = os.getcwd()  \n",
    "sys.path.append(os.path.abspath(os.path.join(notebook_dir, '..')))\n",
    "\n",
    "from Classification import classification_class as classification\n",
    "from Features_extraction import feature_extraction_class as feature_extraction\n",
    "from Data_processing.images_processing_class import ImagesProcessing\n",
    "from utils import perform_classification, best_preprocessing\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0452f6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_results_best_methods = {\n",
    "        \"accuracy\" : {},\n",
    "        \"f1-score\" : {},\n",
    "        \"recall\" : {},\n",
    "        \"precision\" : {},\n",
    "        \"roc_auc\" : {}\n",
    "        }\n",
    "\n",
    "name_best_models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "668a3ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_normal_path = \"../Data/normal/\"\n",
    "data_pothole_path = \"../Data/potholes/\"\n",
    "\n",
    "image_process = ImagesProcessing(folder_normal=data_normal_path, folder_potholes=data_pothole_path, img_size=(256, 256))\n",
    "images = image_process.images\n",
    "Y = image_process.labels\n",
    "df_Y = pd.DataFrame(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5429b921",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_feature_extraction_unprocessed_images = feature_extraction.FeatureExtraction(image_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0d8d6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "\u001b[1mExtracting SIFT Features\u001b[0;0m\n",
      "Performing Classification for SIFT\n",
      "Best method name for SIFT: LogReg\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.85        86\n",
      "           1       0.74      0.78      0.76        50\n",
      "\n",
      "    accuracy                           0.82       136\n",
      "   macro avg       0.80      0.81      0.80       136\n",
      "weighted avg       0.82      0.82      0.82       136\n",
      "\n",
      "============================================\n",
      "\u001b[1mExtracting ORB Features\u001b[0;0m\n",
      "Performing Classification for ORB\n",
      "Best method name for ORB: LogReg\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.63      0.68        86\n",
      "           1       0.48      0.60      0.54        50\n",
      "\n",
      "    accuracy                           0.62       136\n",
      "   macro avg       0.61      0.61      0.61       136\n",
      "weighted avg       0.64      0.62      0.62       136\n",
      "\n",
      "============================================\n",
      "\u001b[1mExtracting Harris Corner Features\u001b[0;0m\n",
      "Performing Classification for Harris\n",
      "Best method name for Harris: RandomForest\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.73      0.79        86\n",
      "           1       0.63      0.78      0.70        50\n",
      "\n",
      "    accuracy                           0.75       136\n",
      "   macro avg       0.74      0.76      0.74       136\n",
      "weighted avg       0.77      0.75      0.75       136\n",
      "\n",
      "============================================\n",
      "\u001b[1mExtracting Edge features\u001b[0;0m\n",
      "Performing Classification for EDGE\n",
      "Best method name for EDGE: LogReg\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.81      0.86        86\n",
      "           1       0.73      0.86      0.79        50\n",
      "\n",
      "    accuracy                           0.83       136\n",
      "   macro avg       0.82      0.84      0.82       136\n",
      "weighted avg       0.84      0.83      0.83       136\n",
      "\n",
      "============================================\n",
      "\u001b[1mData Segmentation using Otsu's Thresholding\u001b[0;0m\n",
      "Performing Classification for Otsu\n",
      "Best method name for Otsu: LogReg\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76        86\n",
      "           1       0.59      0.66      0.62        50\n",
      "\n",
      "    accuracy                           0.71       136\n",
      "   macro avg       0.69      0.70      0.69       136\n",
      "weighted avg       0.71      0.71      0.71       136\n",
      "\n",
      "============================================\n",
      "\u001b[1mData Segmentation using Adaptive's Thresholding\u001b[0;0m\n",
      "Performing Classification for Adaptive\n",
      "Best method name for Adaptive: LogReg\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.48      0.60        86\n",
      "           1       0.48      0.82      0.60        50\n",
      "\n",
      "    accuracy                           0.60       136\n",
      "   macro avg       0.65      0.65      0.60       136\n",
      "weighted avg       0.69      0.60      0.60       136\n",
      "\n",
      "============================================\n",
      "\u001b[1mExtracting Surface Textures Features using Gabor filters\u001b[0;0m\n",
      "Performing Classification for Gabor\n",
      "Best method name for Gabor: RandomForest\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.62      0.63        86\n",
      "           1       0.38      0.40      0.39        50\n",
      "\n",
      "    accuracy                           0.54       136\n",
      "   macro avg       0.51      0.51      0.51       136\n",
      "weighted avg       0.54      0.54      0.54       136\n",
      "\n",
      "============================================\n",
      "\u001b[1mExtracting Spatial Texture Features using LBP\u001b[0;0m\n",
      "Performing Classification for LBP\n",
      "Best method name for LBP: LogReg\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.79      0.83        86\n",
      "           1       0.69      0.82      0.75        50\n",
      "\n",
      "    accuracy                           0.80       136\n",
      "   macro avg       0.79      0.81      0.79       136\n",
      "weighted avg       0.81      0.80      0.80       136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "methods = {\n",
    "    \"SIFT\": env_feature_extraction_unprocessed_images.method_SIFT,\n",
    "    \"ORB\": env_feature_extraction_unprocessed_images.method_ORB,\n",
    "    \"Harris\": env_feature_extraction_unprocessed_images.method_Harris,\n",
    "    \"EDGE\": env_feature_extraction_unprocessed_images.method_EDGE,\n",
    "    \"Otsu\": env_feature_extraction_unprocessed_images.method_otsu,\n",
    "    \"Adaptive\": env_feature_extraction_unprocessed_images.method_adaptive,\n",
    "    \"Gabor\": env_feature_extraction_unprocessed_images.method_Gabor,\n",
    "    \"LBP\": env_feature_extraction_unprocessed_images.method_LBP,\n",
    "    #\"HOG\": env_feature_extraction_unprocessed_images.method_HOG\n",
    "}\n",
    "\n",
    "for method_name, method_function in methods.items():\n",
    "\n",
    "    metrics_results_best_methods = perform_classification(\n",
    "        method_name=method_name, \n",
    "        df_Y=df_Y,\n",
    "        name_best_models=name_best_models,\n",
    "        metrics_results_best_methods=metrics_results_best_methods,\n",
    "        feature_extraction_method=method_function \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ff7ea6",
   "metadata": {},
   "source": [
    "Find best configurations for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e22d9f40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "\u001b[1mExtracting SIFT Features\u001b[0;0m\n",
      "============================================\n",
      "\u001b[1mExtracting SIFT Features\u001b[0;0m\n",
      "============================================\n",
      "\u001b[1mExtracting SIFT Features\u001b[0;0m\n",
      "Best preprocessing configuration for SIFT: {'filter': 'bilateral', 'filter_params': (9, 75, 75), 'histogram': 'clahe', 'normalize': False, 'f1-score': 0.804676279657609}\n",
      "============================================\n",
      "\u001b[1mExtracting ORB Features\u001b[0;0m\n",
      "============================================\n",
      "\u001b[1mExtracting ORB Features\u001b[0;0m\n",
      "============================================\n",
      "\u001b[1mExtracting ORB Features\u001b[0;0m\n",
      "Best preprocessing configuration for ORB: {'filter': 'bilateral', 'filter_params': (9, 75, 75), 'histogram': 'none', 'normalize': False, 'f1-score': 0.6053571428571429}\n",
      "============================================\n",
      "\u001b[1mExtracting Harris Corner Features\u001b[0;0m\n",
      "============================================\n",
      "\u001b[1mExtracting Harris Corner Features\u001b[0;0m\n",
      "============================================\n",
      "\u001b[1mExtracting Harris Corner Features\u001b[0;0m\n",
      "Best preprocessing configuration for Harris: {'filter': 'bilateral', 'filter_params': (5, 50, 50), 'histogram': 'clahe', 'normalize': True, 'f1-score': 0.7614035087719297}\n",
      "============================================\n",
      "\u001b[1mExtracting Edge features\u001b[0;0m\n",
      "============================================\n",
      "\u001b[1mExtracting Edge features\u001b[0;0m\n",
      "============================================\n",
      "\u001b[1mExtracting Edge features\u001b[0;0m\n",
      "Best preprocessing configuration for EDGE: {'filter': 'bilateral', 'filter_params': (9, 75, 75), 'histogram': 'standard', 'normalize': False, 'f1-score': 0.8310749774164408}\n",
      "============================================\n",
      "\u001b[1mExtracting Spatial Texture Features using LBP\u001b[0;0m\n",
      "============================================\n",
      "\u001b[1mExtracting Spatial Texture Features using LBP\u001b[0;0m\n",
      "============================================\n",
      "\u001b[1mExtracting Spatial Texture Features using LBP\u001b[0;0m\n",
      "Best preprocessing configuration for LBP: {'filter': 'gaussian', 'filter_params': ((7, 7), 2), 'histogram': 'clahe', 'normalize': True, 'f1-score': 0.7933247031012551}\n",
      "============================================\n",
      "\u001b[1mExtracting Surface Textures Features using Gabor filters\u001b[0;0m\n",
      "============================================\n",
      "\u001b[1mExtracting Surface Textures Features using Gabor filters\u001b[0;0m\n",
      "============================================\n",
      "\u001b[1mExtracting Surface Textures Features using Gabor filters\u001b[0;0m\n",
      "Best preprocessing configuration for Gabor: {'filter': 'bilateral', 'filter_params': (12, 100, 100), 'histogram': 'none', 'normalize': True, 'f1-score': 0.5748937234308578}\n",
      "============================================\n",
      "\u001b[1mData Segmentation using Otsu's Thresholding\u001b[0;0m\n",
      "============================================\n",
      "\u001b[1mData Segmentation using Otsu's Thresholding\u001b[0;0m\n",
      "============================================\n",
      "\u001b[1mData Segmentation using Otsu's Thresholding\u001b[0;0m\n",
      "Best preprocessing configuration for otsu: {'filter': 'gaussian', 'filter_params': ((7, 7), 2), 'histogram': 'clahe', 'normalize': True, 'f1-score': 0.6908388270061377}\n",
      "============================================\n",
      "\u001b[1mData Segmentation using Adaptive's Thresholding\u001b[0;0m\n",
      "============================================\n",
      "\u001b[1mData Segmentation using Adaptive's Thresholding\u001b[0;0m\n",
      "============================================\n",
      "\u001b[1mData Segmentation using Adaptive's Thresholding\u001b[0;0m\n",
      "Best preprocessing configuration for adaptive: {'filter': 'bilateral', 'filter_params': (5, 50, 50), 'histogram': 'none', 'normalize': True, 'f1-score': 0.6029411764705882}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Change this filter with the good association method-filter find in articles\n",
    "\n",
    "\n",
    "\n",
    "filters = {\n",
    "    \"SIFT\": [\"bilateral\"],  \n",
    "    \"ORB\": [\"bilateral\"],\n",
    "    \"Harris\": [\"bilateral\"],\n",
    "    \"EDGE\": [\"bilateral\"],\n",
    "    \"LBP\": [\"gaussian\"],\n",
    "    \"Gabor\": [\"bilateral\"],\n",
    "    \"otsu\": [\"gaussian\"],\n",
    "    \"adaptive\": [\"bilateral\"]\n",
    "}\n",
    "\n",
    "best_configs = {}\n",
    "\n",
    "for method_name, filter_names in filters.items():\n",
    "    if isinstance(filter_names, list):  \n",
    "        best_configs[method_name] = []\n",
    "        for filter_name in filter_names:\n",
    "            best_config, all_results = best_preprocessing(\n",
    "                image_process,\n",
    "                getattr(env_feature_extraction_unprocessed_images, f\"method_{method_name}\"),\n",
    "                filter_name,\n",
    "                method_name,\n",
    "                n_iter=3,\n",
    "                fixed_histogram_method=\"clahe\" if method_name == \"SIFT\" else None  # âœ… On force CLAHE ici !\n",
    "            )\n",
    "            best_configs[method_name].append(best_config)\n",
    "    else:  \n",
    "        best_config, all_results = best_preprocessing(\n",
    "            image_process,\n",
    "            getattr(env_feature_extraction_unprocessed_images, f\"method_{method_name}\"),\n",
    "            filter_names,\n",
    "            method_name,\n",
    "            n_iter=3\n",
    "        )\n",
    "        best_configs[method_name] = best_config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aad15c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../best_configs_processing.json\", \"w\") as f:\n",
    "    json.dump(best_configs, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5c8c39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
